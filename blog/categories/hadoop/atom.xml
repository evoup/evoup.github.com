<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: hadoop | Evoup`s Blog]]></title>
  <link href="http://evoupsight.com/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://evoupsight.com/"/>
  <updated>2014-02-20T17:00:39+08:00</updated>
  <id>http://evoupsight.com/</id>
  <author>
    <name><![CDATA[Evoup`s Blog]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[hive初试--导入数据和查询]]></title>
    <link href="http://evoupsight.com/blog/2014/02/20/hive-import-data/"/>
    <updated>2014-02-20T10:50:00+08:00</updated>
    <id>http://evoupsight.com/blog/2014/02/20/hive-import-data</id>
    <content type="html"><![CDATA[<p>hive虽然是基于hadoop的map/reduce进行云计算，但是自身需要依赖一个元数据表，要么是derby，要么是mysql，相同点总归是要先导入数据，然后才能进行处理。其原理是把结构化的数据文件映射为一张数据库表，然后将SQL语句转化为MapReduce任务进行运行，以绕过专门开发MapReduce这样一个逆向思维的产物。</p>

<p>Hive不可以改写、插入和删除数据，换句话说hive完全就是用来进行计算的。</p>

<p>Hive的数据是存在hdfs上的,所以数据导入之后除了元数据之外，还有另一份本体数据（通常比较大的）存在hdfs上。</p>

<p>有了基础概念之后，开始正题了。</p>

<!-- more -->


<h3>环境描述</h3>

<p>hadoop0.20.203+hive0.7</p>

<h3>任务描述</h3>

<p>本次目的，是把一张二维表导入到hive中后，然后根据编号查询对应的单词。</p>

<h3>过程描述</h3>

<p>假设有这样一个文件</p>

<p><code>sh
cat test.txt
</code></p>

<p>1   hello
2   world
3   test
4   case</p>

<p>(vim党注意：如果你已经把tab键映射为4个空格，那么请进入插入模式后在数字后ctrl+v,然后按下<tab>键，再输入单词，否则无法完成制表符的键入，数据导入失败。)</p>

<p>启动hive建表:
```sh
hive>  CREATE EXTERNAL TABLE MYTEST(id INT, name STRING)</p>

<blockquote><p>COMMENT &lsquo;this is a test&rsquo;
ROW FORMAT DELIMITED FIELDS TERMINATED BY &lsquo;\t&rsquo;
STORED AS TEXTFILE
LOCATION &lsquo;/data/test&rsquo;;
OK
```
注意这一步要求原本的hdfs目录下没有/data/test文件夹，如果有的话，hive是要报错的。
还有存储格式有三种textfile、rcfile和sequencefile。其中多数情况用textfile就可以了，如果要压缩，可以考虑后两者。</p></blockquote>

<p>进入hadoop，开始导入
<code>sh
/bin/hadoop fs -put test.txt /data/test
</code></p>

<p>回到hive，用简单的HQL查询语句查询id为4的记录
<code>sh
hive&gt; select * from mytest where id = 4;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_201402191826_0007, Tracking URL = http://mdn2.net:50030/jobdetails.jsp?jobid=job_201402191826_0007
Kill Command = /u01/app/hadoop/bin/../bin/hadoop job  -Dmapred.job.tracker=mdn2.net:9025 -kill job_201402191826_0007
2014-02-20 00:16:34,842 Stage-1 map = 0%,  reduce = 0%
2014-02-20 00:16:40,889 Stage-1 map = 100%,  reduce = 0%
2014-02-20 00:16:46,936 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201402191826_0007
OK
4       case
Time taken: 21.36 seconds
</code></p>

<p>hive查询一次需要21秒?没错，这就是MapReduce查询的特点了，换做mysql的话这样查询一次应该是&lt;1秒的。好啦，收工。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[centos5.8下基于hadoop0.20.203的hive0.7安装]]></title>
    <link href="http://evoupsight.com/blog/2014/02/17/hadoop0-dot-20-dot-2-plus-hive0-dot-7/"/>
    <updated>2014-02-17T15:38:00+08:00</updated>
    <id>http://evoupsight.com/blog/2014/02/17/hadoop0-dot-20-dot-2-plus-hive0-dot-7</id>
    <content type="html"><![CDATA[<h3>什么是hive</h3>

<blockquote><p>hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p></blockquote>

<!-- more -->


<h3>hive的安装</h3>

<p>先提一下，之前我的hadoop安装在/u01/app/hadoop目录下，同样的我们下载到改目录下，然后开始安装
注意我的hadoop版本为hadooop-0.20.203.0.tgz，与此匹配的版本为hive0.7.0
<code>sh
cd /u01/app
wget http://archive.apache.org/dist/hive/hive-0.7.1/hive-0.7.1-bin.tar.gz
tar xzf hive-0.7.1-bin.tar.gz
ln -s hive-0.7.1-bin.tar.gz hive
</code></p>

<h4>环境变量设置</h4>

<p>在~/.profile中加入
<code>sh
export HIVE_HOME=/u01/app/hive
export HIVE_CONF_DIR=/u01/app/hive/conf
</code></p>

<p>在系统中指出hive的配置文件所在
<code>sh
export PATH=$HIVE_HOME/bin:PATH
</code>
这个实现输入hive，hive service就会自动相应，而不用输入hive所在的绝对路径。
<code>sh
export HIVE_LIB=$HIVE_HOME/lib
</code></p>

<p>记得用source让profile生效
<code>sh
source ~/.profile
</code></p>

<p>然后是进行hive配置文件的配置
<code>sh
cd /u01/app/hive/conf
cp hive-env.sh.template hive-env.sh
vim hive-env.sh
</code></p>

<h4>安装依赖软件</h4>

<p>发现有2种安装方式，一种是derby,另一种是mysql，这里先介绍mysql方式</p>

<blockquote><p>关于什么是derby: 这是一个apache DB的子项目，是一个完全用java实现的开源关系型数据库。这里就不使用了，我们采用mysql。</p></blockquote>

<h4>安装mysql</h4>

<p><code>sh
//卸载老版本的mysql软件包
yum remove mysql mysql-*
//安装mysql5.5的源
rpm -Uvh http://repo.webtatic.com/yum/centos/5/latest.rpm
//安装MySQL客户端的支持包
yum install libmysqlclient15 --enablerepo=webtatic
//安装MySQL 5.5的客户端和服务端
yum install mysql55 mysql55-server --enablerepo=webtatic
//启动MySQL系统服务，更新数据库
/etc/init.d/mysqld restart
mysql_upgrade
</code></p>

<h4>修改mysql用户密码</h4>

<p>```sh</p>

<h1>mysql -u root mysql   //默认的没有密码直接进去的</h1>

<p>mysql>use mysql;
mysql>desc user;
mysql> GRANT ALL PRIVILEGES ON <em>.</em> TO root@&ldquo;%&rdquo; IDENTIFIED BY &ldquo;root&rdquo;;　　//为root添加远程连接的能力。
mysql>update user set Password = password(&lsquo;xxxxxx&rsquo;) where User=&lsquo;root&rsquo;;
mysql>select Host,User,Password  from user where User=&lsquo;root&rsquo;;
mysql>flush privileges;
mysql>exit
```</p>

<h4>设置mysql为开机自动启动</h4>

<p><code>sh
sudo /sbin/chkconfig --add mysqld
sudo /sbin/chkconfig mysqld on
</code></p>

<h4>开始配置</h4>

<p>在conf目录下创建hive-site.xml</p>

<p>创建hive数据库给hive做元数据表
<code>sh
create database hive;
grant all privileges on *.* to hive@localhost identified by 'hive';
flush privileges;
</code></p>

<p>运行hive
```sh
cd /u01/app/hive
/bin/hive
Exception in thread &ldquo;main&rdquo; java.lang.NoClassDefFoundError: jline/ArgumentCompletor$ArgumentDelimiter</p>

<pre><code>    at java.lang.Class.forName0(Native Method)
    at java.lang.Class.forName(Class.java:247)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:149)
</code></pre>

<p>Caused by: java.lang.ClassNotFoundException: jline.ArgumentCompletor$ArgumentDelimiter</p>

<pre><code>    at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
    at java.security.AccessController.doPrivileged(Native Method)
    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
    ... 3 more
</code></pre>

<p>```
这个只需要把hive/lib下的jline-0.9.94.jar复制到$HADOOP/lib下即可。</p>

<p>再次启动
```sh
bin/hive
Exception in thread &ldquo;main&rdquo; java.lang.NoClassDefFoundError: org/apache/hadoop/hive/conf/HiveConf</p>

<pre><code>    at java.lang.Class.forName0(Native Method)
    at java.lang.Class.forName(Class.java:247)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:149)
</code></pre>

<p>Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf</p>

<pre><code>    at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
    at java.security.AccessController.doPrivileged(Native Method)
    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
</code></pre>

<p>```</p>

<p>需要修改$HADOOP/conf/的hadoop-env.sh中的
<code>sh
export HADOOP_CLASSPATH=$HBASE_HOME/hbase-0.90.3.jar:$HBASE_HOME:$HBASE_HOME/lib/zookeeper-3.2.2.jar:$HBASE_HOME/conf
</code></p>

<p>改成</p>

<p><code>sh
export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$HBASE_HOME/hbase-0.90.3.jar:$HBASE_HOME:$HBASE_HOME/lib/zookeeper-3.2.2.jar:$HBASE_HOME/conf
</code></p>

<p>然后可以启动hive了
<code>sh
bin/hive
WARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201402170220_1889385824.txt
hive&gt;
</code>
有警告，估计是jdk我用的1.7导致的，可以先不管，接下来可以试试hive的操作了。</p>

<p>•建立测试表test
```sh</p>

<blockquote><p>create table test (key string);
show tables;
FAILED: Error in metadata: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory
NestedThrowables:
java.lang.reflect.InvocationTargetException
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
```</p></blockquote>

<p>原来如果mysql用rpm安装，还需要一个jar包mysql-connector-java-5.15-bin.jar，然后拷贝到hive的lib目录下可以。</p>

<p>``sh</p>

<blockquote><p>show tables;
OK
Time taken: 0.082 seconds
```</p></blockquote>

<p>一个表也没有，创建表吧
···sh</p>

<blockquote><p>create table test (key string);
FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.ipc.RemoteException org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /user/hive/warehouse/test. Name node is in safe mode.
```</p></blockquote>

<p>namenode为什么是安全模式？
hadoop启动的时候是在安全模式，查看一下现在的模式状态
<code>sh
bin/hadoop dfsadmin –safemode get
ON
</code></p>

<p>那就关了
<code>sh
bin/hadoop dfsadmin -safemode leave
</code></p>

<p>再次查看
<code>sh
bin/hadoop dfsadmin –safemode get
OFF
</code></p>

<p>已经关了，再次建表测试
<code>sh
bin/hive
hive&gt; create table test (key string);
OK
Time taken: 0.521 seconds
hive&gt; show tables;
OK
test
Time taken: 0.14 seconds
</code></p>

<h3>参考文章</h3>

<p><a href="http://blog.163.com/huang_zhong_yuan/blog/static/174975283201181371146365/">http://blog.163.com/huang_zhong_yuan/blog/static/174975283201181371146365/</a></p>

<p><a href="http://hi.baidu.com/allense7en/item/db8e5b4fb177aae81e19bcb4">http://hi.baidu.com/allense7en/item/db8e5b4fb177aae81e19bcb4</a></p>

<p><a href="http://www.cnblogs.com/zhanghuijunjava/archive/2013/04/22/hadoop_HDFS.html">http://www.cnblogs.com/zhanghuijunjava/archive/2013/04/22/hadoop_HDFS.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[hbase连zookeeper瞬断]]></title>
    <link href="http://evoupsight.com/blog/2013/12/31/hbase-access-zookeeper-fail-too-many-connections-form-ip/"/>
    <updated>2013-12-31T11:48:00+08:00</updated>
    <id>http://evoupsight.com/blog/2013/12/31/hbase-access-zookeeper-fail-too-many-connections-form-ip</id>
    <content type="html"><![CDATA[<h3>问题</h3>

<p>今天修理hbase问题的时候发现，监控的60010端口的master.jsp就是无法显示，进入log查看发现zookeeper连上了之后马上就断开。</p>

<p><code>[NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn$Factory@247]</code>
<code>- Too many connections from /10.10.8.136 - max is 10</code></p>

<p>这种情况在telnet测试中被证实，一连上也是瞬间脱离与服务器的连接。</p>

<!-- more -->


<h3>解决</h3>

<p>其实需要在zoo.cfg中加入maxClientCnxns=300，加完以后需要重启。问题解决。</p>

<h3>原因</h3>

<p>我们线上有24台节点，但是这个参数竟然是使用默认的10，导致更多的客户端连上了zookeeper导致namenode的自带管理页无法连接到zookeeper，进而无法显示该页面。</p>

<p>如何监控zookeeper的其他指标，这里列出zoo.cfg的配置文件
```
dataDir = 数据存放路径</p>

<p>dataLogDir = 日志存放路径</p>

<p>clientPort = 客户端连接端口</p>

<p>clientPortAddress</p>

<p>tickTime= 整型 不能为0</p>

<p>maxClientCnxns= 整型 最大客户端连接数</p>

<p>minSessionTimeout= 整型</p>

<p>maxSessionTimeout= 整型</p>

<p>initLimit = 整型</p>

<p>syncLimit = 整型</p>

<p>electionAlg = 整型</p>

<p>peerType = observer | participant</p>

<p>server. sid= host:port | host:port:port  | host:port:port:type (type值 observer | participant)</p>

<p>group.gid = sid:sid (一个ID， 值是多个sid, 中间以:分割， 一个sid只能属于一个gid)</p>

<p>weight.sid=整型
```
可以看出还有至少2个参数是需要考虑的minSessionTimeout和maxSessionTimeout需要调优，得用JMX监控一段时间得出结论了。</p>

<p>同样的发现thrift也存在类似一连就断开的问题，下篇博文再作分析。</p>

<h3>总结</h3>

<p>这个案例告诉我不要盲目认为按照默认参数配置就没问题了，那是给小批量测试用的，需要根据实际情况采取相应配置。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HBASE完全分布式搭建(VMware版)]]></title>
    <link href="http://evoupsight.com/blog/2013/11/04/hbase-full-distributed-case/"/>
    <updated>2013-11-04T16:28:00+08:00</updated>
    <id>http://evoupsight.com/blog/2013/11/04/hbase-full-distributed-case</id>
    <content type="html"><![CDATA[<p>接上一篇<a href="http://evoupsight.com/blog/2013/11/04/hadoop-full-distributed-case/">《HADOOP完全分布式搭建(VMware版)》</a></p>

<p>参考 <a href="http://www.cnblogs.com/flyoung2008/archive/2011/12/02/2272761.html">http://www.cnblogs.com/flyoung2008/archive/2011/12/02/2272761.html</a></p>

<!-- more -->


<p><code>bash
cd /u01/app
tar xzf hbase-0.90.6.tgz
ln -s hbase-0.90.6 hbase
cd hbase/conf
</code></p>

<p>编辑hbase-env.sh
<code>bash
export HBASE_OPTS="-ea -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode"
export JAVA_HOME=/usr/java/jdk1.6.0_29
export HBASE_MANAGES_ZK=true
</code></p>

<p>注意HADOOP_HOME和HBASE_HOME已经在~/.profile中指定，不需要再设置了。</p>

<hr />

<p>(补充：2014-2-19 发现这么写还不能加载，放到~/.bashrc中才对，见下)
<code>bash
export HADOOP_HOME=/u01/app/hadoop
</code></p>

<hr />

<p>编辑hbase-site.xml
```xml
&lt;?xml version=&ldquo;1.0&rdquo;?>
&lt;?xml-stylesheet type=&ldquo;text/xsl&rdquo; href=&ldquo;configuration.xsl&rdquo;?></p>

<!--
/**
 * Copyright 2010 The Apache Software Foundation
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->


<p><configuration></p>

<pre><code>&lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://mdn2.net:9024/hbase&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.master&lt;/name&gt;
    &lt;value&gt;mdn2.net:60000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;mdn2.net,mdn2_datanode1.net,mdn2_datanode2.net&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p></configuration>
```</p>

<p>注意点：
 1.其中首先需要注意hdfs://mdn2.net:9024/hbase这里，必须与你的Hadoop集群的core-site.xml文件配置保持完全一致才行，如果你Hadoop的hdfs使用了其它端口，请在这里也修改。再者就是Hbase该项并不识别机器IP，只能使用机器hostname才可行，即若使用IP是会抛出java错误。
 2.hbase.zookeeper.quorum 的个数必须是奇数。</p>

<p>修改regionservers文件（同hadoop的slaves文件）
<code>bash
mdn2_datanode1.net
mdn2_datanode2.net
</code></p>

<p>然后分发到各点，就可以启动了。</p>

<p><code>bash
bin/start hbase
bin/hbase shell
</code></p>

<p>报错
ERROR: org.apache.hadoop.hbase.ZooKeeperConnectionException: HBase is able to connect to ZooKeeper but the connection closes immediately. This could be a sign that the server has too many connections (30 is the default). Consider inspecting your ZK server logs for that error and then make sure you are reusing HBaseConfiguration as often as you can. See HTable&rsquo;s javadoc for more information.
看来不要使用hbase托管的zookeeper转而再装一个试试。</p>

<p><code>bash
wget http://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.4/zookeeper-3.4.4.tar.gz
</code></p>

<p>编辑~/.profile,加入关于zk环境变量的设置</p>

<p><code>bash
export ZOOKEEPER_HOME="/u01/app/zookeeper/"
PATH=$ZOOKEEPER_HOME/bin:$PATH
export PATH
cd /u01/app/zookeeper/conf
cp zoo_sample.cfg zoo.cfg
cd ../bin
./zkServer.sh start
</code></p>

<p>最后重启整个hadoop/hbase搞定，jps看下跑的进程。收工。</p>

<p><img src="/images/evoup/hbase_vmware.png" alt="Alt text" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HADOOP0.20.203完全分布式搭建(VMware版)]]></title>
    <link href="http://evoupsight.com/blog/2013/11/04/hadoop0dot2dot203-full-distributed-case/"/>
    <updated>2013-11-04T15:28:00+08:00</updated>
    <id>http://evoupsight.com/blog/2013/11/04/hadoop0dot2dot203-full-distributed-case</id>
    <content type="html"><![CDATA[<p>vmware版本8.0.4 build-744019
首先准备3台虚拟机</p>

<p><img src="/images/evoup/hadoop_vmware.png" alt="Alt text" /></p>

<p><code>
 ,''''''''''''':'''''''''''''''''':'''''''''''''''''''''''''''''''''''|
 |    usage    |        IP        |             Hostname              |
 |             |                  |                                   |
 |'''''''''''''|''''''''''''''''''|'''''''''''''''''''''''''''''''''''|
 | namenode    | 192.168.174.132  |           mdn2.net                |
 |             |                  |                                   |
 |'''''''''''''|''''''''''''''''''|'''''''''''''''''''''''''''''''''''|
 | datanode01  | 192.168.174.135  |        mdn2_datanode1.net         |
 |             |                  |                                   |
 |'''''''''''''|''''''''''''''''''|'''''''''''''''''''''''''''''''''''|
 | datanode02  | 192.168.174.136  |        mdn2_datanode2.net         |
 |             |                  |                                   |
  '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
</code></p>

<p> <!-- more --></p>

<p>Ps:
为节省资源关闭点不必要的服务
```bash</p>

<h1>!/bin/bash</h1>

<p>for SERVICES in abrtd acpid auditd avahi-daemon cpuspeed haldaemon mdmonitor messagebus udev-post;
do /sbin/chkconfig ${SERVICES} off;
done
```</p>

<h3>准备工作</h3>

<p>先安装JDK1.6
linux:先把已经安装的openjdk卸载,安装sun jdk1.6 （j2se就够了）
```bash</p>

<h1>rpm -qa | grep jdk</h1>

<p>java-1.6.0-openjdk-1.6.0.0-1.28.1.10.9.el5_8</p>

<h1>rpm -e java-1.6.0-openjdk-1.6.0.0-1.28.1.10.9.el5_8</h1>

<h1>sudo chmod +x jdk-6u35-linux-x64-rpm.bin</h1>

<h1>./jdk-6u35-linux-x64-rpm.bin</h1>

<p>```</p>

<p>freebsd:直接在/usr/port/java/diablo-jdk16，不要装jdk16，打好几个补丁还编译通不过，浪费时间！）</p>

<p>hadoop所有操作都是用hadoop帐号，下面添加</p>

<p>```bash
linux:# groupadd hadoop
freebsd:# pw groupadd hadoop
linux:# useradd -r -g hadoop -d /home/hadoop -m -s /bin/bash hadoop
freebsd:# pw adduser hadoop -g hadoop -d /home/hadoop -m -s /bin/bash</p>

<p>all:# mkdir -p /u01/app
all:# chgrp -R hadoop /u01/app
all:# chown -R hadoop /u01/app
```</p>

<p>环境变量
<code>bash
all:$ vi ~/.profile
all:export HADOOP_HOME=/u01/app/hadoop
all:export HBASE_HOME=/u01/app/hbase
</code>
（补充2014-2-19，也可以放到~/.bashrc中，~/.profile有时不能加载比较奇怪）</p>

<p>进行免密码的ssh登录设置
<code>bash
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
</code>
到此准备工作完成</p>

<p>安装Hadoop
<code>bash
all:$ cd /u01/app
all:$ tar zxf hadoop-0.20.203.0rc1.tar.gz
all:$ ln -s hadoop-0.20.203.0 hadoop
</code></p>

<h3>正式开始</h3>

<p>编辑所有机器的/etc/hosts文件（host的centos下为/etc/sysconfig/network，bsd的要设置/etc/rc.conf）
(PS:也可以选择现在namenode上编辑好了，分发到其他机器上去)</p>

<p>```bash</p>

<h1>Do not remove the following line, or various programs</h1>

<h1>that require network functionality will fail.</h1>

<p>127.0.0.1       localhost.localdomain localhost
::1             localhost6.localdomain6 localhost6
192.168.174.132 mdn2.net
192.168.174.135 mdn2_datanode1.net
192.168.174.136 mdn2_datanode2.net
```</p>

<p>假定已经安装好了JAVA，编辑hadoop帐号的profile文件加入如下代码
<code>bash
export HADOOP_HOME=/u01/app/hadoop
export HBASE_HOME=/u01/app/hbase
export PATH="/usr/java/jdk1.6.0_37/bin/:$PATH"
export JAVA_HOME="/usr/java/jdk1.6.0_37/bin/"
</code></p>

<p>下载hadoop解压之后，在hadoop-env.sh指定java的目录
<code>bash
export JAVA_HOME=/usr/java/jdk1.6.0_37/
</code></p>

<p>再编辑core-site.xml
```xml
&lt;?xml version=&ldquo;1.0&rdquo;?>
&lt;?xml-stylesheet type=&ldquo;text/xsl&rdquo; href=&ldquo;configuration.xsl&rdquo;?></p>

<!-- Put site-specific property overrides in this file. -->


<p><configuration></p>

<pre><code>&lt;property&gt;
    &lt;name&gt;fs.default.name&lt;/name&gt;
    &lt;value&gt;hdfs://mdn2.net:9024&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/u01/app/hadoopTmp&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p></configuration>
```</p>

<p>注意：hadoop.tmp.dir是hadoop文件系统依赖的基础配置，很多路径都依赖它。它默认的位置是在/tmp/{$user}下面，在local和hdfs都会建有相同的目录，但是在/tmp路径下的存储是不安全的，因为linux一次重启，文件就可能被删除。导致namenode启动不起来。</p>

<p>再编辑hdfs-site.xml
```xml
&lt;?xml version=&ldquo;1.0&rdquo;?>
&lt;?xml-stylesheet type=&ldquo;text/xsl&rdquo; href=&ldquo;configuration.xsl&rdquo;?></p>

<!-- Put site-specific property overrides in this file. -->


<p><configuration></p>

<pre><code>&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.data.dir&lt;/name&gt;
    &lt;value&gt;/u01/app/hdfsdata&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p></configuration>
```</p>

<p>注意：dfs.data.dir为hdfs实际存放数据的路径，这个配置只对本地有效，中间可以用,连接多个目录</p>

<p>master里
<code>bash
mdn2.net
</code></p>

<p>slaves里
<code>bash
mdn2_datanode1.net
mdn2_datanode2.net
</code></p>

<p>注意点：
修改hadoop-0.20.203.0/bin下的hadoop.
vi  hadoop
查找 –jvm . vi 下的命令模式： :/-jvm
将-jvm server改成 –server .
因为JDK1.6已经废除了一个参数-jvm,如果不修改的话，无法启动数据节点。</p>

<p>到namenode上格式化hdfs
<code>bash
/bin/hadoop namenode -format
</code>
注意9024为hdfs通讯端口，完全分布式环境下，可以直接将防火墙关闭
<code>bash
sudo /etc/init.d/iptables stop
sudo /sbin/chkconfig iptables off
</code>
启动：
<code>bash
bin/start-all.sh
</code>
或者只启动dfs和mapreduce
<code>bash
bin/start-dfs.sh
bin/start-mapred.sh
</code>
最后发一个jps的进程图</p>

<p><img src="/images/evoup/hadoop_vmware01.png" alt="Alt text" /></p>
]]></content>
  </entry>
  
</feed>
