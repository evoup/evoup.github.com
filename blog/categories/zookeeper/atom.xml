<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: zookeeper | Evoup`s Blog]]></title>
  <link href="http://evoupsight.com/blog/categories/zookeeper/atom.xml" rel="self"/>
  <link href="http://evoupsight.com/"/>
  <updated>2016-12-06T14:41:19+08:00</updated>
  <id>http://evoupsight.com/</id>
  <author>
    <name><![CDATA[Evoup`s Blog]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[zookeeper伪分布配置安装]]></title>
    <link href="http://evoupsight.com/blog/2014/07/30/zookeeper-pseudo-distributed-installation/"/>
    <updated>2014-07-30T17:22:00+08:00</updated>
    <id>http://evoupsight.com/blog/2014/07/30/zookeeper-pseudo-distributed-installation</id>
    <content type="html"><![CDATA[<h3 id="section">场景</h3>
<p>我的开发机是在vmware的centos6.5上搭建了一个hadoop节点来做开发，现在想在项目中加入zookeeper做HA的功能（一个leader，多个follower），一开始想到的是再搞一台机器实现完全分布，为了一个zookeeper其实不用再搞一台机器节省资源，后来考虑了下其实还有个伪分布的概念，所谓伪分布就是在一台机器上启动多个实例。下文详细描述如何在一台机器上启动多个zookeeper实例实现伪分布zk集群。</p>

<!-- more -->

<h3 id="section-1">伪分布集群安装配置</h3>
<p>准备一台机器，假定IP为192.168.216.198。</p>

<h4 id="section-2">下载安装软件</h4>

<p><code>bash
$ cd /home/hadoop/software
$ wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz
$ tar xzf zookeeper-3.4.5.tar.gz
$ sudo mv zookeeper-3.4.5 /usr/local/
$ sudo mv /usr/local/zookeeper-3.4.5/ /usr/local/zookeeper
</code></p>

<h4 id="myid">配置三个实例的myid</h4>

<p><code>bash
$ mkdir -p /home/hadoop/zoo/zk1 /home/hadoop/zoo/zk2 /home/hadoop/zoo/zk3
$ echo "1" &gt; /home/hadoop/zoo/zk1/myid
$ echo "2" &gt; /home/hadoop/zoo/zk2/myid
$ echo "3" &gt; /home/hadoop/zoo/zk3/myid
</code></p>

<h4 id="section-3">分配制作三个配置文件</h4>

<p>```bash
$ sudo cp /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo1.cfg
$ sudo cp /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo2.cfg
$ sudo cp /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo3.cfg</p>

<p>$ sudo vim /usr/local/zookeeper/conf/zoo1.cfg 
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/home/hadoop/zoo/zk1/
clientPort=2181
server.1=192.168.216.198:2889:3888
server.2=192.168.216.198:2889:3889
server.3=192.168.216.198:2890:3890</p>

<p>$sudo vim usr/local/zookeeper/conf/zoo2.cfg 
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/home/hadoop/zoo/zk2/
clientPort=2182
server.1=192.168.216.198:2889:3888
server.2=192.168.216.198:2889:3889
server.3=192.168.216.198:2890:3890</p>

<p>$sudo vim /usr/local/zookeeper/conf/zoo3.cfg
/usr/local/zookeeper/conf/zoo3.cfg:tickTime=2000
/usr/local/zookeeper/conf/zoo3.cfg:initLimit=10
/usr/local/zookeeper/conf/zoo3.cfg:syncLimit=5
/usr/local/zookeeper/conf/zoo3.cfg:dataDir=/home/hadoop/zoo/zk3/
/usr/local/zookeeper/conf/zoo3.cfg:clientPort=2183
/usr/local/zookeeper/conf/zoo3.cfg:server.1=192.168.216.198:2889:3888
/usr/local/zookeeper/conf/zoo3.cfg:server.2=192.168.216.198:2889:3889
/usr/local/zookeeper/conf/zoo3.cfg:server.3=192.168.216.198:2890:3890
```</p>

<h4 id="section-4">给当前用户账户访问权限（可选）</h4>

<p><code>bash
$ sudo chown -R hadoop:hadoop /usr/local/zookeeper
</code></p>

<h4 id="section-5">启动集群</h4>

<p><code>bash
$ /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo1.cfg
JMX enabled by default
Using config: /usr/local/zookeeper/conf/zoo1.cfg
Starting zookeeper ... STARTED
$ /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo2.cfg
JMX enabled by default
Using config: /usr/local/zookeeper/conf/zoo2.cfg
Starting zookeeper ... STARTED
$ /usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo3.cfg
JMX enabled by default
Using config: /usr/local/zookeeper/conf/zoo3.cfg
Starting zookeeper ... STARTED
[hadoop@mdn4namenode1 zk1]$ jps
3115 Jps
3084 QuorumPeerMain
3043 QuorumPeerMain
3015 QuorumPeerMain
</code></p>

<h4 id="zookeeper">查看zookeeper工作文件目录结构</h4>

<p>```bash
$ ls -R /home/hadoop/zoo/
/home/hadoop/zoo/:
zk1  zk2  zk3</p>

<p>/home/hadoop/zoo/zk1:
myid  version-2  zookeeper.out  zookeeper_server.pid</p>

<p>/home/hadoop/zoo/zk1/version-2:
acceptedEpoch  currentEpoch  snapshot.0</p>

<p>/home/hadoop/zoo/zk2:
myid  version-2  zookeeper_server.pid</p>

<p>/home/hadoop/zoo/zk2/version-2:
acceptedEpoch  currentEpoch  snapshot.0</p>

<p>/home/hadoop/zoo/zk3:
myid  version-2  zookeeper_server.pid</p>

<p>/home/hadoop/zoo/zk3/version-2:
acceptedEpoch  currentEpoch  snapshot.100000000
```</p>

<h4 id="zookeeper-1">查看zookeeper运行情况</h4>

<p><code>bash
/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zoo1.cfg
/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zoo2.cfg
/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zoo3.cfg
</code></p>

<p>报错，需要修正zkServer.sh
把</p>

<p><code>bash
    #STAT=`$JAVA "-Dzookeeper.log.dir=${ZOO_LOG_DIR}" "-Dzookeeper.root.logger=${ZOO_LOG4J_PROP}" \
             #-cp "$CLASSPATH" $JVMFLAGS org.apache.zookeeper.client.FourLetterWordMain localhost \
             #$(grep "^[[:space:]]*clientPort" "$ZOOCFG" | sed -e 's/.*=//') srvr 2&gt; /dev/null    \
          #| grep Mode`
</code></p>

<p>给注释了，然后在其下加一行</p>

<p><code>bash
    STAT=`echo stat | nc 127.0.0.1 $(grep clientPort "$ZOOCFG" | sed -e 's/.*=//') 2&gt; /dev/null| grep Mode`
</code></p>

<p>这样就妥妥的了:)</p>

<p><code>bash
$ /usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zoo1.cfg
JMX enabled by default
Using config: /usr/local/zookeeper/conf/zoo1.cfg
Mode: follower
$ /usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zoo2.cfg
JMX enabled by default
Using config: /usr/local/zookeeper/conf/zoo2.cfg
Mode: leader
$ /usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zoo3.cfg
JMX enabled by default
Using config: /usr/local/zookeeper/conf/zoo3.cfg
Mode: follower
</code></p>

<h4 id="section-6">加入启动项</h4>

<p><code>bash
sudo vim /etc/rc.d/rc.local
#!/bin/sh
su - hadoop -c "/usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo1.cfg"
su - hadoop -c "/usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo2.cfg"
su - hadoop -c "/usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo3.cfg"
</code></p>

<p>收工。</p>

<h4 id="section-7">参考资料</h4>
<p><a href="http://blog.fens.me/hadoop-zookeeper-intro/">《ZooKeeper伪分布式集群安装及使用 | 粉丝日志》</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[hadoop2.0cdh4.6.0完全分布式安装]]></title>
    <link href="http://evoupsight.com/blog/2014/07/10/hadoop2-dot-0cdh4-dot-6-0-fullly-distrbute/"/>
    <updated>2014-07-10T15:57:00+08:00</updated>
    <id>http://evoupsight.com/blog/2014/07/10/hadoop2-dot-0cdh4-dot-6-0-fullly-distrbute</id>
    <content type="html"><![CDATA[<p>hadoop2.0 cdh4安装（完全分布式）</p>

<!-- more -->

<p>vmware版本8.0.4 build-744019</p>

<p>首先规划3台虚拟机</p>

<p><code>bash
 ,'''''''''''''''''''''':'''''''''''''''''':''''''''''''''''''''''''''''''''''''''''''''|
 |        usage         |        IP        |                  Hostname                  |
 |                      |                  |                                            |
 |''''''''''''''''''''''|''''''''''''''''''|''''''''''''''''''''''''''''''''''''''''''''|
 | namenode1,datanode1  | 192.168.216.183  |    mdn3namenode1.net,mdn3datanode1.net     |
 |                      |                  |                                            |
 |''''''''''''''''''''''|''''''''''''''''''|''''''''''''''''''''''''''''''''''''''''''''|
 | namenode2,datanode2  | 192.168.216.184  |    mdn3namenode2.net,mdn3datanode2.net     |
 |                      |                  |                                            |
 |''''''''''''''''''''''|''''''''''''''''''|''''''''''''''''''''''''''''''''''''''''''''|
 | datanode2,nfs server | 192.168.216.185  |    mdn3datanode3.net,mdn3nfsserver.net     |
 |                      |                  |                                            |
  '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
</code></p>

<h3 id="section">准备工作</h3>

<p>先安装JDK1.6 linux:先把已经安装的openjdk卸载,安装sun jdk1.6,去oracle下载 （j2se就够了）</p>

<p><code>bash
$ rpm -qa | grep jdk
java-1.6.0-openjdk-1.6.0.0-1.28.1.10.9.el5_8
$ sudo rpm -e java-1.6.0-openjdk-1.6.0.0-1.28.1.10.9.el5_8
$ sudo chmod +x jdk-6u45-linux-x64-rpm.bin
$ sudo ./jdk-6u45-linux-x64-rpm.bin
</code></p>

<p>hadoop所有操作都是用hadoop帐号，下面添加（如果已经创建了帐号无须添加）</p>

<p>```bash
$ groupadd hadoop
$ useradd -r -g hadoop -d /home/hadoop -m -s /bin/bash hadoop</p>

<p>$ mkdir -p /home/hadoop
$ chgrp -R hadoop /home/hadoop
$ chown -R hadoop /home/hadoop
```</p>

<p>环境变量(在centos里不管编辑~/.profile还是~/.bash_profile都不能加载环境变量，正确的应该是在~/.bashrc中，而如果是root用户，应该可以直接在/etc/profile中编辑)</p>

<p><code>bash
$ vi ~/.bashrc 
export HADOOP_HOME="/usr/local/hadoop"
export JAVA_HOME="/usr/java/jdk1.6.0_45"
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
</code></p>

<p>切换到hadoop帐号，进行免密码的ssh登录设置</p>

<p><code>bash
$ su hadoop
$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
$ chmod 600 ~/.ssh/authorized_keys
</code></p>

<p>给出我的hadoop/hbase版本</p>

<p>```bash
Name        : hadoop-hdfs-namenode
Arch        : x86_64
Version     : 2.0.0+1554
Release     : 1.cdh4.6.0.p0.16.el6</p>

<p>Name        : hbase-master
Arch        : x86_64
Version     : 0.94.15+86
Release     : 1.cdh4.6.0.p0.14.el6
```</p>

<p>然后是cdh的软件下载url
http://archive.cloudera.com/cdh4
这个路径下有很多的软件。</p>

<p>下载cdh4.6的几个包安装</p>

<p><code>bash
$ cd /home/software/
$ wget http://archive.cloudera.com/cdh4/cdh/4/hadoop-2.0.0-cdh4.6.0.tar.gz
$ sudo mkdir /usr/local/hadoop/
$ tar xzf hadoop-2.0.0-cdh4.6.0.tar.gz 
$ sudo mv hadoop-2.0.0-cdh4.6.0 /usr/local/
$ sudo mv /usr/local/hadoop-2.0.0-cdh4.6.0 /usr/local/hadoop
$ sudo chown -R hadoop:hadoop /usr/local/hadoop
</code>
创建存储临时文件temp、data和name节点数据的目录</p>

<p><code>bash
$ sudo mkdir /usr/local/hadoop/temp/ /usr/local/hadoop/data/ /usr/local/hadoop/name/ 
$ sudo chown -R hadoop:hadoop /usr/local/hadoop
</code></p>

<p>好了，准备工作终了</p>

<p>开始配置
配置/usr/local/hadoop/etc/hadoop/core-site.xml</p>

<p>```xml</p>
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://mdn3namenode1.net:9000</value> <!-- master域名或者master的ip -->
        </property>
        <property>
                <name>io.file.buffer.size</name>
                <value>131072</value>
        </property>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>file:/usr/local/hadoop/temp</value>
                <description>Abase for other temporary directories.</description>
        </property>
        <property>
                <name>hadoop.proxyuser.hduser.hosts</name>
                <value>*</value>
        </property>
        <property>
                <name>hadoop.proxyuser.hduser.groups</name>
                <value>*</value>
        </property>
</configuration>
<p>```</p>

<p>配置/usr/local/hadoop/etc/hadoop/hdfs-site.xml</p>

<p>```xml</p>
<configuration>
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>mdn3namenode1.net:9001</value> <!-- master域名或者master的ip -->
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
        <value>file:/usr/local/hadoop/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/usr/local/hadoop/dfs/data</value>
        </property>
        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>
        <property>
                <name>dfs.webhdfs.enabled</name>
                <value>true</value>
        </property>
</configuration>
<p>```</p>

<p>配置/usr/local/hadoop/etc/hadoop/madpred-site.xml</p>

<p><code>bash
cp mapred-site.xml.template mapred-site.xml
</code></p>

<p>```xml</p>
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.address</name>
                <value>mdn3namenode1.net:10020</value> <!-- master域名或者master的ip -->
        </property>
        <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>mdn3namenode1.net:19888</value> <!-- master域名或者master的ip -->
        </property>
</configuration>
<p>```</p>

<p>配置/usr/local/hadoop/etc/hadoop/yarn-site.xml</p>

<p>```xml</p>
<configuration>
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce.shuffle</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
                <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
        <property>
                <name>yarn.resourcemanager.address</name>
                <value>mdn3namenode1.net:8032</value> <!-- master域名或者master的ip -->
        </property>
        <property>
                <name>yarn.resourcemanager.scheduler.address</name>
                <value>mdn3namenode1.net:8030</value> <!-- master域名或者master的ip -->
        </property>
        <property>
                <name>yarn.resourcemanager.resource-tracker.address</name>
                <value>mdn3namenode1.net:8031</value> <!-- master域名或者master的ip -->
        </property>
        <property>
                <name>yarn.resourcemanager.admin.address</name>
                <value>mdn3namenode1.net:8033</value> <!-- master域名或者master的ip -->
        </property>
        <property>
                <name>yarn.resourcemanager.webapp.address</name>
                <value>mdn3namenode1.net:8088</value> <!-- master域名或者master的ip -->
        </property>
</configuration>
<p>```</p>

<p>编辑slave的名字
直接讲slave的域名或者slave的ip按照一行一个的规则写进去</p>

<p><code>bash
mdn3datanode2.net
mdn3datanode3.net
</code></p>

<p>复制到各台机器上</p>

<p><code>bash
$ cd /usr/local/
$ sudo scp -dr hadoop@192.168.216.183:/usr/local/hadoop .
$ sudo chown -R hadoop:hadoop hadoop/
</code></p>

<p>格式化hdfs
在namenode上执行</p>

<p><code>bash
/usr/local/hadoop/bin/hadoop namenode -format
</code></p>

<h3 id="hbase">hbase的安装配置</h3>
<p>hbase依赖zookeeper，需要先去下载</p>

<p><code>bash
$ cd /home/software/
$ wget http://archive.cloudera.com/cdh4/cdh/4/zookeeper-3.4.5-cdh4.6.0.tar.gz
$ tar xzf zookeeper-3.4.5-cdh4.6.0.tar.gz
$ sudo mv zookeeper-3.4.5-cdh4.6.0 /usr/local/
$ sudo mv /usr/local/zookeeper-3.4.5-cdh4.6.0 /usr/local/zookeeper
$ sudo chown -R hadoop:hadoop /usr/local/zookeeper
$ sudo cp /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo.cfg
</code>
zookeeper准备完毕，可以继续安装hbase</p>

<p><code>bash
$ cd /home/software/
$ wget http://archive.cloudera.com/cdh4/cdh/4/hbase-0.94.15-cdh4.6.0.tar.gz
$ sudo mkdir /usr/local/hbase/
$ tar xzf hbase-0.94.15-cdh4.6.0.tar.gz
$ sudo mv hbase-0.94.15-cdh4.6.0 /usr/local/
$ sudo mv /usr/local/hbase-0.94.15-cdh4.6.0 /usr/local/hbase
$ sudo chown -R hadoop:hadoop /usr/local/hbase
</code></p>

<p>若干配置步骤
配置hbase-site.xml</p>

<p>```xml</p>
<configuration>
    <property>
        <name>hbase.rootdir</name>
        <value>hdfs://mdn3namenode1.net:9000/hbase</value>

    </property>
    <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
    </property>
    <property>
        <name>hbase.master</name>
        <value>mdn3datanode1.net:60000</value>
    </property>
    <property>
        <name>hbase.zookeeper.quorum</name>
        <value>mdn3datanode1.net</value>    <!-- 这里配置若干个zookeeper的服务器地址，需要是奇数个 -->
    </property>
</configuration>
<p>```</p>

<p>配置hbase-env.sh</p>

<p><code>bash
export HBASE_MANAGES_ZK=false
</code></p>

<p>不要hbase托管zookeeper</p>

<p>配置regionservers</p>

<p><code>bash
mdn3datanode2.net
mdn3datanode3.net
</code></p>

<p>启动hbase</p>

<p><code>bash
/usr/local/hbase/bin/start-hbase.sh
/usr/local/hbase/bin/hbase-daemons.sh start thrift
</code>
hbase启动完成.</p>

<h3 id="hbase-1">配置hbase可能碰到几个问题的说明：</h3>
<p>1) 报错
` ERROR client.HConnectionManager$HConnectionImplementation: Check the value configured in ‘zookeeper.znode.parent’ `</p>

<p>是需要把/etc/hosts中的127.0.0.1注释掉，否则zookeeper还会出现
最后的hosts我这里是这样</p>

<p><code>bash
[hadoop@localhost conf]$ more /etc/hosts
#127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.216.183 mdn3namenode1.net mdn3datanode1.net
192.168.216.184 mdn3namenode2.net mdn3datanode2.net
192.168.216.185 mdn3datanode3.net mdn3nfsserver.net
</code></p>

<p>2) 在运行/usr/local/hbase/bin/hbase shell的时候出现了
` WARN conf.Configuration: hadoop.native.lib is deprecated. Instead, use io.native.lib.available `</p>

<p>3) ` java.net.ConnectException: Connection refused `
这是要求hadoop中的slaves配置和hbase的regionservers要一致。</p>

<h3 id="hive">hive的安装</h3>

<p><code>bash
cd /home/software
wget http://archive.cloudera.com/cdh4/cdh/4/hive-0.10.0-cdh4.6.0.tar.gz
tar xzf hive-0.10.0-cdh4.6.0.tar.gz
sudo mv hive-0.10.0-cdh4.6.0 /usr/local/
sudo mv /usr/local/hive-0.10.0-cdh4.6.0 /usr/local/hive
chown -R hadoop:hadoop /usr/local/hive
</code></p>

<h3 id="hive-1">hive的配置</h3>
<p>在~/.bashrc中加入</p>

<p><code>bash
export HIVE_HOME=/usr/local/hive
export HIVE_CONF_DIR=$HIVE_HOME/conf
export HIVE_LIB=$HIVE_HOME/lib
export PATH=$PATH:$JAVA_HOME/bin:$ZOOKEEPER_HOME:$HIVE_HOME
</code></p>

<p>在conf/hive-site.xml中</p>

<p>```xml</p>
<configuration>
<property>
  <name>hive.metastore.local</name>
  <value>true</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://localhost:3306/hive</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>com.mysql.jdbc.Driver</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>hive</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>hive</value>
</property>
<property>
  <name>datanucleus.fixedDatastore</name>
  <value>false</value>
</property>

</configuration>
<p>```</p>

<p>这里要安装mysql作为元数据服务器，参考这篇 http://evoupsight.com/blog/2014/02/17/hadoop0-dot-20-dot-2-plus-hive0-dot-7/</p>

<p>然后/bin/hive后，成功进入shell</p>

<p><code>bash
&gt; create table test (key string);
</code></p>

<p>如果遇到下面的报错
` FAILED: Error in metadata: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient `</p>

<p><code> FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask </code>
建表错误
开始以为hive没有访问mysql的权限,以root用户登录mysql然后赋予hive用户权限：</p>

<p><code>sql
grant all privileges on *.* to hive@localhost identified by 'hive';
grant all privileges on *.* to hive@192.168.216.183 identified by 'hive';
</code></p>

<p>发现问题依旧</p>

<p>其实是要在hive-site.xml中把</p>

<p>```xml</p>
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://localhost:3306/hive</value>
</property>
<p>```</p>

<p>改成</p>

<p>```xml</p>
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://192.168.216.183:3306/hive</value>
</property>
<p>```</p>

<p>问题依旧，打开hive的调试模式</p>

<p><code>bash
bin/hive -hiveconf hive.root.logger=DEBUG,console
</code></p>

<p><code> 14/05/08 17:35:53 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. </code>
` Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore `</p>

<p>在配置文件里删除hive.metastore.local属性。</p>

<p>最后查得原因是没有安装mysql驱动，只要把mysql-connector-java-5.1.22-bin.jar放到lib下就可以了</p>

<p>然后</p>

<p>```bash
hive&gt; create table test (key string);
OK
Time taken: 42.259 seconds</p>

<p>hive&gt; show tables;
OK
test
Time taken: 0.279 seconds
```</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[hbase连zookeeper瞬断]]></title>
    <link href="http://evoupsight.com/blog/2013/12/31/hbase-access-zookeeper-fail-too-many-connections-form-ip/"/>
    <updated>2013-12-31T11:48:00+08:00</updated>
    <id>http://evoupsight.com/blog/2013/12/31/hbase-access-zookeeper-fail-too-many-connections-form-ip</id>
    <content type="html"><![CDATA[<h3 id="section">问题</h3>

<p>今天修理hbase问题的时候发现，监控的60010端口的master.jsp就是无法显示，进入log查看发现zookeeper连上了之后马上就断开。</p>

<p><code> [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn$Factory@247] </code> 
` - Too many connections from /10.10.8.136 - max is 10 `</p>

<p>这种情况在telnet测试中被证实，一连上也是瞬间脱离与服务器的连接。</p>

<!-- more -->

<h3 id="section-1">解决</h3>

<p>其实需要在zoo.cfg中加入maxClientCnxns=300，加完以后需要重启。问题解决。</p>

<h3 id="section-2">原因</h3>

<p>我们线上有24台节点，但是这个参数竟然是使用默认的10，导致更多的客户端连上了zookeeper导致namenode的自带管理页无法连接到zookeeper，进而无法显示该页面。</p>

<p>如何监控zookeeper的其他指标，这里列出zoo.cfg的配置文件</p>

<p>```bash
dataDir = 数据存放路径</p>

<p>dataLogDir = 日志存放路径</p>

<p>clientPort = 客户端连接端口</p>

<p>clientPortAddress</p>

<p>tickTime= 整型 不能为0</p>

<p>maxClientCnxns= 整型 最大客户端连接数</p>

<p>minSessionTimeout= 整型</p>

<p>maxSessionTimeout= 整型</p>

<p>initLimit = 整型</p>

<p>syncLimit = 整型</p>

<p>electionAlg = 整型</p>

<table>
  <tbody>
    <tr>
      <td>peerType = observer</td>
      <td>participant</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>server. sid= host:port</td>
      <td>host:port:port</td>
      <td>host:port:port:type (type值 observer</td>
      <td>participant)</td>
    </tr>
  </tbody>
</table>

<p>group.gid = sid:sid (一个ID， 值是多个sid, 中间以:分割， 一个sid只能属于一个gid)</p>

<p>weight.sid=整型
```</p>

<p>可以看出还有至少2个参数是需要考虑的minSessionTimeout和maxSessionTimeout需要调优，得用JMX监控一段时间得出结论了。</p>

<p>同样的发现thrift也存在类似一连就断开的问题，下篇博文再作分析。</p>

<h3 id="section-3">总结</h3>
<p>这个案例告诉我不要盲目认为按照默认参数配置就没问题了，那是给小批量测试用的，需要根据实际情况采取相应配置。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[php和zookeeper交互获取hbase的master状态]]></title>
    <link href="http://evoupsight.com/blog/2013/03/25/php-zookeeper/"/>
    <updated>2013-03-25T10:54:00+08:00</updated>
    <id>http://evoupsight.com/blog/2013/03/25/php-zookeeper</id>
    <content type="html"><![CDATA[<h3 id="zookeeper">为什么要使用zookeeper扩展</h3>
<p>公司用了HHVM这玩意来编译php，其实我要给它NO，因为连zookeeper都没支持，如果要支持，要自己写扩展，这是一个奇葩的节奏。所以我们还是采用php脚本方式来调用pecl扩展来实现php和zookeeper通讯。
<!-- more --></p>

<h3 id="section">扩展</h3>
<p>以下是php的pecl版zookeeper扩展的下载地址http://pecl.php.net/get/zookeeper-0.2.2.tgz<br />
可以看到php版本的要求是&gt;5.2.0</p>

<p><code>bash
cd /home/software
wget http://pecl.php.net/get/zookeeper-0.2.2.tgz
tar xzf zookeeper-0.2.2.tgz
</code></p>

<h3 id="section-1">依赖库</h3>
<p>很可惜，该扩展的安装还需要你先去在本地下好zookeeper依赖库，那么我们开始吧。首先是zookeeper的安装，去apache下载好并解压<br /></p>

<p><code>bash
cd /home/software
wget http://apache.fayea.com/apache-mirror/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
tar xzf zookeeper-3.4.6.tar.gz
cd zookeeper-3.4.6/src/c
./configure --prefix=/home/software/zookeeper-3.4.6/prefix
sudo make install
</code></p>

<h3 id="php">php端编译</h3>
<p>这里就给一个静态编译的例子好了,以最新版本的php5.3.8为例，进入源码文件夹后</p>

<p><code>bash
$ cd /home/software/php-5.3.8/
$ cp -r /home/software/zookeeper-0.2.2 ext/zookeeper
$ ls ext/zookeeper/
CREDITS                 LICENSE                 config.m4               php_zookeeper.c         php_zookeeper_private.h php_zookeeper_session.h zoo_lock.h
ChangeLog               README.markdown         examples                php_zookeeper.h         php_zookeeper_session.c zoo_lock.c              zookeeper-api.php
$ ./buildconf -force
$ './configure'  '--prefix=/usr/local/php5.3.8_zookeeper' '--enable-zookeeper' '--with-libzookeeper-dir=/home/software/zookeeper-3.4.3/prefix' '--enable-sockets'
$ make
$ sudo make install
</code></p>

<p>安装完成后查看是否支持</p>

<p><code>bash
$ /usr/local/php5.3.8._zookeeper/bin/php -i | grep 'libzookeeper version'
libzookeeper version =&gt; 3.4.3
</code>
看到已经支持了</p>

<h3 id="section-2">最终的获取</h3>
<p>找一台非托管zk的hbase，这里假设是127.0.0.1，端口为2181</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="o">&amp;</span><span class="nx">lt</span><span class="p">;</span><span class="o">?</span><span class="nx">php</span>
</span><span class='line'><span class="k">class</span> <span class="nc">zookeeper_instance</span> <span class="k">extends</span> <span class="nx">Zookeeper</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">function</span> <span class="nf">connect_cb</span><span class="p">(</span><span class="nv">$type</span><span class="p">,</span> <span class="nv">$event</span><span class="p">,</span> <span class="nv">$string</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">if</span> <span class="p">(</span><span class="nv">$event</span> <span class="o">==</span> <span class="nx">Zookeeper</span><span class="o">::</span><span class="na">CONNECTED_STATE</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>            <span class="nv">$acl</span><span class="o">=</span><span class="k">array</span><span class="p">(</span>
</span><span class='line'>                <span class="err">“</span><span class="nx">perms</span><span class="err">”</span><span class="o">=&amp;</span><span class="nx">gt</span><span class="p">;</span><span class="mh">0x1f</span><span class="p">,</span>
</span><span class='line'>                <span class="err">“</span><span class="nx">scheme</span><span class="err">”</span><span class="o">=&amp;</span><span class="nx">gt</span><span class="p">;</span><span class="err">”</span><span class="nx">world</span><span class="err">”</span><span class="p">,</span>
</span><span class='line'>                <span class="err">“</span><span class="nx">id</span><span class="err">”</span><span class="o">=&amp;</span><span class="nx">gt</span><span class="p">;</span><span class="err">”</span><span class="nx">anyone</span><span class="err">”</span>
</span><span class='line'>            <span class="p">);</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span><span class="o">&lt;/</span><span class="nx">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="nx">p</span><span class="o">&gt;</span><span class="nv">$zk</span><span class="o">=</span><span class="k">new</span> <span class="nx">zookeeper_instance</span><span class="p">();</span>
</span><span class='line'><span class="k">echo</span> <span class="err">“</span><span class="nx">instance</span> <span class="nx">ok\n</span><span class="err">”</span><span class="p">;</span><span class="o">&lt;/</span><span class="nx">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="nx">p</span><span class="o">&gt;</span><span class="nv">$zk</span><span class="o">-&amp;</span><span class="nx">gt</span><span class="p">;</span><span class="nx">connect</span><span class="p">(</span><span class="err">“</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span><span class="o">:</span><span class="mi">2181</span><span class="err">”</span><span class="p">,</span> <span class="k">array</span><span class="p">(</span><span class="nv">$zk</span><span class="p">,</span> <span class="err">‘</span><span class="nx">connect_cb</span><span class="err">’</span><span class="p">),</span><span class="mi">200000</span><span class="p">);</span> <span class="c1">//连接超时200秒,比较夸张，测试用：）</span>
</span><span class='line'><span class="k">echo</span> <span class="err">“</span><span class="nx">connect</span> <span class="nx">ok\n</span><span class="err">”</span><span class="p">;</span>
</span><span class='line'><span class="nv">$zkm</span><span class="o">=</span><span class="nv">$zk</span><span class="o">-&amp;</span><span class="nx">gt</span><span class="p">;</span><span class="nx">get</span><span class="p">(</span><span class="err">“</span><span class="o">/</span><span class="nx">hbase</span><span class="o">/</span><span class="nx">master</span><span class="err">”</span><span class="p">);</span>
</span><span class='line'><span class="nb">print_r</span><span class="p">(</span><span class="nv">$zkm</span><span class="p">);</span>
</span><span class='line'><span class="o">?&amp;</span><span class="nx">gt</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>查看结果,已经获取到了master</p>

<p><code>bash
[yin@yin-arch php_zookeeper_sample]&gt;/usr/home/yin/local/bin/php5_new/bin/php test_zk_gethbasemaster.php
instance ok
connect ok
▒25469@namenode1namenode1,60000,1395387861310[yin@yin-arch php_zookeeper_sample]&gt;
</code></p>

<p>收工!</p>
]]></content>
  </entry>
  
</feed>
